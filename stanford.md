I am writing this statement to fulfill my application of the M.S. in Computer Science program. I plan to focus my graduate study on Reinforcement Learning and Knowledge Representation, especially on one of these two topics: Multi-Agent Cooperation and Neural Symbolic Systems. I would like to pursue a successful career by studying in your distinguished program for which I have long prepared myself to be eligible.

My motivation for Reinforcement Learning comes from the ambition of developing agents that possess human-level intelligence and know how to cooperate. For the last two years, I have been heavily involving myself in exploring Deep Reinforcement Learning and recently set foot on Symbolic Systems. During the period of my study and research, I gradually established my perspective of those methodologies and believe that introducing Symbolic Systems in the current Deep Reinforcement Learning framework is indispensable to developing human-level intelligence. Therefore, It's my strong desire to study in your program, as I shall greatly benefit from your expertise and knowledge in Symbolic Systems.

The starting point of my adventure in Artificial Intelligence was taking the online courses CS188 and CS294 by UC Berkeley [footnotes]. The courses introduced traditional approaches such as A* search and HMM, as well as advanced topics like Neural Networks and Reinforcement Learning. %This was when I started to learn about concepts such as agents and representations, triggering me to further explore the field.
To apply what I learned in practice, I participated in the 2017 Microsoft Malmo Collaborative AI challenge where participants were required to design an agent that collaborated with another to corner a pig in a fence. Popular Deep Reinforcement Learning models such as DQN and A3C failed to achieve satisfying performance on this task, primarily due to the sparsity of the reward signals and inferring the intention of an unknown-behavior collaborator. To tackle this issue, I designed a particle filter module to track the collaborator's behavior and a hierarchical manager-worker system that learned to select long-term strategies. Our team eventually won the second place of the competition for the performance and novelty of our method. However, plenty of task-specific rules were handcrafted in the particle filter module to infer the belief of the collaborator, so the problem of cooperation under imperfect information circumstances technically remained unsolved.

Despite I followed many works about multi-agent cooperation after the competition, the problem continually baffled me until I got the opportunity to attend the exchange study program at the University of Alberta, an institution that pioneers in the research of Artificial Intelligence and Reinforcement Learning. Aside from adapting myself to its undergraduate study, I also took advantage of the office hours to discuss the issue with some brilliant minds there such as Prof. Rich Sutton, and I benefited a lot from their insights. I gradually learned that despite Deep Learning greatly scaled the capability of Reinforcement Learning, tasks that involved reasoning and cooperation under imperfect information circumstances still require a world model to represent the shared knowledge of different agents, which is essential to the development of human-level intelligence. Since then, my attention shifted from multi-agent cooperation to knowledge representation.

Suggested by my research supervisor, Prof. Martha White, I started to investigate Knowledge Distillation, a technique that transfers knowledge from a learned model (teacher) to a new one (student). Fascinated by the idea as it could be useful for solving the knowledge representation problem mentioned above, I spent a year on this project and was determined to understand the underlying mechanism of distillation. During this time, I first came up with a new distillation paradigm, where local constraints were applied on the last hidden layer of a learned neural network to construct sparse embedding that capture the substructures in the data, which later became my Machine Learning course project. I subsequently tried methods such as clustering, auto-encoders and GANs to further exploit the semantics of the embedding, yet none of them led to meaningful results. The results frustrated me but the experience gave me a deeper understanding of Neural Networks: The difficulty of factorizing the high-level representations learned by the neural nets limited its utility in representing and transferring the knowledge across different tasks and agents. Despite that I failed to unravel the mystery of distillation, I discovered that the teacher model's prediction can be converted into a prior distribution over classes where importance sampling can be applied to accelerate training of the student model. My mentor and I later wrote it into a paper and submitted to CVPR-2019. Through this project and submission, I acquired fundamental skills for doing scientific researches such as conducting experiments, keeping track of papers and state-of-art ideas, scientific writing and so forth.

Apart from doing research in Deep Learning and Reinforcement Learning, I also involved myself in many applications of AI to sharpen my practical skills, such as my 6-month internship in Machine Learning group of Microsoft Research Asia (MSRA).  The project I participated in was to apply Deep Learning algorithms to build a Genetic Variant Calling (GVC) tool on Azure Cloud Platform. I was assigned to the job of optimizing the Smith-Waterman algorithm for local realignment between DNA sequences on GPUs, as well as leveraging the existing models to improve the performance of our own variant calling tool, achieving 99.74% test accuracy on the whole human genome. Through my study and work along different areas of AI, I gradually discovered that compared to GVC and other topics like GANs or adversarial examples, making contributions to establishing Artificial General Intelligence is a more prospective and attractive field to me. It inspired my pursuit in Deep Reinforcement Learning (DRL) and decision to set foot on Symbolic Systems which in my belief is essential to knowledge representation.

I learned about Neural Symbolic Systems during my internship in MSRA. The combination of discrete representations and flexible learning system renders great potential use in reasoning and leveraging the common knowledge. I also wrote a detailed article [footnotes] about Neural Symbolic Systems on Medium to share my deliberation on the subject. For graduate study, I would like to explore the efficacy of Symbolic Systems in Deep Reinforcement Learning. As stressed in your program, the best theories of mind and intelligence will emerge by studying the relationship between agents and their environment. The unique opportunity to approach the Artificial General Intelligence in a highly interdisciplinary fashion deeply aligns with my career goal of being a researcher in both AI and Cognitive Science. I'm confident that my previous research and work experience have prepared me well for the graduate study and qualify me as a competent choice of your esteemed program.

I am writing this statement to fulfill my application of the M.S. in Computer Science program. I plan to focus my graduate study on Reinforcement Learning and Knowledge Representation, especially on Neural Symbolic Systems for Multi-Agent Reinforcement Learning. I would like to pursue a successful career by studying in your distinguished program for which I have long prepared myself to be eligible.

My passion for Knowledge Representation and Reinforcement Learning was established through my adventure in Artificial Intelligence and Machine Learning, which was originally started from a multi-agent cooperation contest. During my sophormore year, I took the online courses CS188 and CS294 by UC Berkeley, as well as CS229 and CS231n by Stanford online [footnotes]. These courses covered from traditional approaches such as A* search and HMM to advanced topics like Neural Networks and Reinforcement Learning. To apply what I had learned, I participated in the Microsoft MALMO Collaborative AI challenge [footnotes] where participants were required to design an agent that collaborated with another to corner a pig in a fence. Popular Deep Reinforcement Learning models such as DQN and A3C failed to achieve satisfying performance on this task, primarily due to the sparsity of the reward signals and inferring the intention of an unknown-behavior collaborator. To tackle this issue, I designed a particle filter module to track the collaborator's behavior and a hierarchical manager-worker system that learned to select long-term strategies. Our team eventually won the second place of the competition for the performance and novelty of our method. However, plenty of task-specific rules were handcrafted in the particle filter module to infer the belief of the collaborator, so the problem of cooperation under imperfect information circumstances technically remained unsolved. This problem continually baffled me until I got the opportunity to attend the exchange study program at the University of Alberta, a prestigious institution that pioneers in the research of Artificial Intelligence and Reinforcement Learning.

Aside from adapting myself to the exchange study, I also took advantage of the office hours to discuss the issues that I met in the contest with some brilliant minds there such as Prof. Rich Sutton and Prof. Michael Bowling. I benefited a lot from their insights and I learned that despite that Deep Learning greatly scaled the capability of Reinforcement Learning, tasks that involved reasoning and cooperation under imperfect information circumstances still require good world models to represent the mental states and knowledge shared by agents across different tasks. Meanwhile, I happened to take a lecture on Knowledge Distillation, a technique that transfers knowledge from a learned model (teacher) to a new one (student), which I deemed would be helpful to understand how to represent knowledge for deep learning agents. Since then, my attention temporarily shifted from Multi-Agent Cooperation to Knowledge Distillation.

Supervised by my mentor Prof. Martha White at the University of Alberta, I spent a year on this project as I was determined to understand the underlying mechanism of knowledge distillation. During this time, I first came up with a new distillation paradigm for neural networks, where the student model mimicked a sparse embedding constructed from the teacher's model's last layer, which later became my Machine Learning course project. To improve this method, I subsequently tried out many other approaches such as clustering and auto-encoders, yet none of them led to significant improvement over the original distillation paradigm. The result frustrated me but it also gave me a deeper understanding of Neural Networks and Knowledeg Representation: The difficulty of factorizing the high-level representations limited its utility in representing and transferring knowledge across different tasks and agents.

Despite that I failed to unravel the mystery of distillation, in the experiments I found that the teacher model's prediction can be converted into a prior distribution over classes where importance sampling can be applied to accelerate training of the student model. My mentor and I later wrote it into a paper and submitted to CVPR-2019. Through this project and submission, I acquired fundamental skills for doing scientific researches such as conducting experiments, keeping track of papers and state-of-art ideas, scientific writing and so forth. More importantly, it motivated me to learn about knowledge representation in Symbolic Systems which are composite of atomic rules and tokens, making them more interpretable than neural networks.

Before I started to explore the field of Symbolic Systems, I took a 6-month internship in Machine Learning group of Microsoft Research Asia (MSRA) to sharpen my practical skills. The project I participated in was to apply Deep Learning algorithms to build a Genetic Variant Calling (GVC) tool on Azure Cloud Platform. I was assigned to the job of optimizing the Smith-Waterman algorithm for local realignment between DNA sequences on GPUs, as well as leveraging the existing models to improve the performance of our own variant calling tool, achieving 99.74\% test accuracy on the whole human genome. Moreover, I also got a chance to discuss my thoughts with researchers in MSRA who worked on Deep Reinforcement Learning and Symbolic Systems, which strengthened my resolve to explore these fields, as the combination of discrete representations of knowledge and flexible learning system should render great potential use in reasoning and leveraging the common knowledge for multi-agent systems.

The hybrid model of symbols and neural networks has long been a common-held idea, yet there's only scant amount of implementations for multi-agent systems. For now, I am undergoing an apprenticeship in DeeplyCurious, a start-up company that focuses on Neural Symbolic System in real applications. As for my graduate study, I would like to concentrate on building a hybrid knowledge base of symbols and neural networks for Multi-Agent Reinforcement Learning system. The courses offered by your MSCS program such as CS 394F, CS 394N and CS 394R provide unique opportunities to prepare myself for the aforementioned research. In addition, professors in the CS faculties of UT-Austin such as Prof. Peter Stone, whose work on Multi-Agent Reinforcement Learning deeply aligns with my academic interests, also render students with great environment and guidance for their research. As for myself, I'm confident that my previous study and work experience have prepared me well for the graduate study and qualify me as a competent choice of your esteemed program.

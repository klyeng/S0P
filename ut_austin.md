\noindent I am writing this statement to fulfill my application of the M.S. in Computer Science program. I plan to focus my graduate study on Reinforcement Learning and Knowledge Representation, especially on Neural Symbolic Systems for Multi-Agent Reinforcement Learning. I would like to pursue a successful career by studying in your distinguished program for which I have long prepared myself to be eligible.\\

\noindent My passion for Knowledge Representation and Reinforcement Learning was established through my adventure in Artificial Intelligence and Machine Learning, which was originally started from a multi-agent cooperation contest. During my sophormore year, I took CS188 and CS294 by UC Berkeley [footnotes]. These courses covered both traditional approaches such as A* search and HMM, as well as advanced topics like Neural Networks and Reinforcement Learning. To apply my knowledge into practice, I participated in the Microsoft MALMO Collaborative AI challenge [footnotes]. The contest required participants to design an agent that collaborated with another to corner a pig in a fence. Popular Deep Reinforcement Learning models such as DQN and A3C failed to achieve satisfying performance on this task, primarily due to the sparsity of the reward signals and inferring the intention of an unknown-behavior collaborator. To tackle this issue, I designed a particle filter module to track the collaborator's behavior and a hierarchical manager-worker system that learned to select long-term strategies. Our team eventually won the second place of the competition for the performance and novelty of our method. However, plenty of task-specific rules were handcrafted in the particle filter module to infer the belief of the collaborator, so the problem of cooperation under imperfect information circumstances technically remained unsolved. This problem continued to baffled me until I got the opportunity to attend the exchange study program at the University of Alberta, a prestigious institution that pioneers in the research of Artificial Intelligence and Reinforcement Learning.\\

\noindent Aside from adapting myself to the exchange study, I also took advantage of the office hours to discuss the issues that I met in the contest with some brilliant minds there such as Prof. Rich Sutton and Prof. Martha White. I benefited a lot from their insights and I learned that despite that Deep Learning greatly scaled the capability of Reinforcement Learning, tasks that involved reasoning and cooperation under imperfect information circumstances still require good world models to represent the mental states and knowledge shared by agents across different tasks. So I started to learn about knowledge reprentation and model-based Reinforcement Learning. Coincidently, I happened to take a lecture on Knowledge Distillation, a technique that transfers knowledge from a learned model (teacher) to a new one (student). My intuition makes me believe that it would be helpful to understand knowledge representations in learning systems. Therefore, my attention temporarily shifted from Multi-Agent Cooperation to Knowledge Distillation since then.\\

\noindent Supervised by my mentor Prof. Martha White at the University of Alberta, I spent a year on this project as I was determined to understand the underlying mechanism of knowledge distillation. During this time, I first came up with a new distillation paradigm for neural networks, where the student model mimicked a sparse embedding constructed from the teacher's model's last layer. To improve this method, I subsequently tried out many other approaches such as clustering and auto-encoders, yet none of them led to significant improvement over the original distillation paradigm. Although the result was disappointing, I acquired a deeper understanding of Neural Networks and Knowledge Representation: The difficulty of factorizing the high-level representations limited its utility in representing and transferring knowledge across different tasks and agents.\\

\noindent Despite that I failed to unravel the mystery of knowledge distillation, in the experiments I found that the teacher model's prediction can be converted into a prior distribution over classes where importance-sampling can be applied to accelerate training of the student model. My mentors and I later wrote it into a paper and submitted to AAAI-2019. Through this project and submission, I acquired fundamental skills for doing scientific researches such as conducting experiments, keeping track of papers and state-of-art ideas, scientific writing and so forth. More importantly, it motivated me to dig deeper into symbolic knowledge representation. Such form of knowledge is composite of atomic rules and tokens, making them more interpretable than neural networks.\\ %To get more hand-on experiences in Symbolic Systems, I re-implemented the Conceptual Graph Learning model[footnotes], which extracted educational concepts from websites and automated curricular planning.\\

\noindent But before I started to explore the field of Symbolic Systems, I took a 6-month internship in Machine Learning group of Microsoft Research Asia (MSRA) to sharpen my practical skills. The project I participated in was to apply Deep Learning algorithms to build a Genetic Variant Calling (GVC) tool on Azure Cloud Platform. I was assigned to the job of optimizing the Smith-Waterman algorithm for local realignment between DNA sequences on GPUs, as well as leveraging the existing models to improve the performance of our own variant calling tool. As a result, I achieved a 99.74\% test accuracy on the whole human genome. Moreover, I also got a chance to discuss my thoughts with researchers in MSRA who worked on Deep Reinforcement Learning and Symbolic Systems. They pointed out that the combination of discrete representations of knowledge and flexible learning system should render great use for multi-agent systems. And after further investigation into the area, I decided to pursue it in my graduate study.\\

\noindent The hybrid model of symbols and neural networks has long been a common-held idea, yet only a scant amount of implementations for multi-agent systems are available. For now, I am undergoing an apprenticeship in DeeplyCurious, a start-up company that focuses on Neural Symbolic System in real applications. As for my graduate study, I would like to concentrate on building a hybrid knowledge base of symbols and neural networks for Multi-Agent Reinforcement Learning system. The courses offered by your MSCS program such as CS 394F, CS 394N and CS 394R provide unique opportunities to prepare myself for the aforementioned research. In addition, professors in the CS faculties of UT-Austin such as Prof. Peter Stone, whose work on Multi-Agent Reinforcement Learning deeply aligns with my academic interests, also render students with great environment and guidance for their research. As for myself, I'm confident that my previous study and work experience have prepared me well for the graduate study and qualify me as a competent choice of your esteemed program.
